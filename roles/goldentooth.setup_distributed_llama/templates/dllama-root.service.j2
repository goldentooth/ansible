[Unit]
Description=Distributed LLaMA Root Node
Documentation=https://github.com/b4rtaz/distributed-llama
After=network-online.target
Wants=network-online.target
{% if 'consul' in groups %}
After=consul.service
Wants=consul.service
{% endif %}

[Service]
Type=oneshot
RemainAfterExit=no
User={{ distributed_llama.user }}
Group={{ distributed_llama.group }}
ExecStart={{ distributed_llama.install_dir }}/bin/start-dllama-root.sh
StandardOutput=journal
StandardError=journal

# Resource limits  
MemoryMax=4G
CPUQuota=90%

# Security settings
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths={{ distributed_llama.install_dir }} {{ distributed_llama.models_dir }}
PrivateTmp=true
PrivateDevices=true
ProtectKernelTunables=true
ProtectKernelModules=true
ProtectControlGroups=true

# Environment
Environment=DLLAMA_THREADS={{ distributed_llama.threads }}
Environment=DLLAMA_MODELS_DIR={{ distributed_llama.models_dir }}
Environment=DLLAMA_BUFFER_FLOAT_TYPE={{ distributed_llama.buffer_float_type }}
Environment=DLLAMA_MAX_SEQ_LEN={{ distributed_llama.max_seq_len }}

[Install]
WantedBy=multi-user.target