[Unit]
Description=Distributed LLaMA Worker Node
Documentation=https://github.com/b4rtaz/distributed-llama
After=network-online.target
Wants=network-online.target
{% if 'consul' in groups %}
After=consul.service
Wants=consul.service
{% endif %}

[Service]
Type=exec
User={{ distributed_llama.user }}
Group={{ distributed_llama.group }}
ExecStart={{ distributed_llama.install_dir }}/bin/start-dllama-worker.sh
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal

# Resource limits
MemoryMax=2G
CPUQuota=80%

# Security settings
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths={{ distributed_llama.install_dir }} {{ distributed_llama.models_dir }}
PrivateTmp=true
PrivateDevices=true
ProtectKernelTunables=true
ProtectKernelModules=true
ProtectControlGroups=true

# Environment
Environment=DLLAMA_THREADS={{ distributed_llama.threads }}
Environment=DLLAMA_PORT={{ distributed_llama.worker_port }}
Environment=DLLAMA_MODELS_DIR={{ distributed_llama.models_dir }}

[Install]
WantedBy=multi-user.target